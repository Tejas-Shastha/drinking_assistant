<html><head><meta http-equiv="Content-Type" content="text/html;charset=utf-8">
<title>drinking_assistant: feeder_offline_training Namespace Reference</title>
<link href="doxygen.css" rel="stylesheet" type="text/css">
<link href="tabs.css" rel="stylesheet" type="text/css">
<script type="text/javascript" src="jquery.js"></script>
</head>
<body onload='searchBox.OnSelectItem(0);'>
<!-- Generated by Doxygen 1.8.6 -->
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li class="current"><a href="namespaces.html"><span>Namespaces</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
    </ul>
  </div>
  <div id="navrow2" class="tabs2">
    <ul class="tablist">
      <li><a href="namespaces.html"><span>Namespace&#160;List</span></a></li>
      <li><a href="namespacemembers.html"><span>Namespace&#160;Members</span></a></li>
    </ul>
  </div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#func-members">Functions</a> &#124;
<a href="#var-members">Variables</a>  </div>
  <div class="headertitle">
<div class="title">feeder_offline_training Namespace Reference</div>  </div>
</div><!--header-->
<div class="contents">
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:a6b2e776b125a379926ab2906f86c071e"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacefeeder__offline__training.html#a6b2e776b125a379926ab2906f86c071e">policy_eval</a></td></tr>
<tr class="separator:a6b2e776b125a379926ab2906f86c071e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4dfb6a04eab78e4c049f70307b2025ef"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacefeeder__offline__training.html#a4dfb6a04eab78e4c049f70307b2025ef">policy_iteration</a></td></tr>
<tr class="separator:a4dfb6a04eab78e4c049f70307b2025ef"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae6f2b6c5fc2ee36749b23735b7510238"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacefeeder__offline__training.html#ae6f2b6c5fc2ee36749b23735b7510238">policyMatrixToVector</a></td></tr>
<tr class="separator:ae6f2b6c5fc2ee36749b23735b7510238"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6c77911f829708330dcce88228788bdd"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacefeeder__offline__training.html#a6c77911f829708330dcce88228788bdd">value_iteration</a></td></tr>
<tr class="separator:a6c77911f829708330dcce88228788bdd"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="var-members"></a>
Variables</h2></td></tr>
<tr class="memitem:a6f72d1398884834aeb54ed5d16c326ba"><td class="memItemLeft" align="right" valign="top">tuple&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacefeeder__offline__training.html#a6f72d1398884834aeb54ed5d16c326ba">pi_pi_star</a> = <a class="el" href="namespacefeeder__offline__training.html#ae6f2b6c5fc2ee36749b23735b7510238">policyMatrixToVector</a>(<a class="el" href="namespacefeeder__offline__training.html#a1d53a65de36fee8cbe6d35f10af91a31">pol_iter_policy</a>[0])</td></tr>
<tr class="separator:a6f72d1398884834aeb54ed5d16c326ba"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a39f347ada3f7a0614cff24945645320a"><td class="memItemLeft" align="right" valign="top">list&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacefeeder__offline__training.html#a39f347ada3f7a0614cff24945645320a">PI_pi_star_file</a> = sys.argv[2]</td></tr>
<tr class="separator:a39f347ada3f7a0614cff24945645320a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1d53a65de36fee8cbe6d35f10af91a31"><td class="memItemLeft" align="right" valign="top">tuple&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacefeeder__offline__training.html#a1d53a65de36fee8cbe6d35f10af91a31">pol_iter_policy</a> = <a class="el" href="namespacefeeder__offline__training.html#a4dfb6a04eab78e4c049f70307b2025ef">policy_iteration</a>(<a class="el" href="namespacefeeder__offline__training.html#a6b2e776b125a379926ab2906f86c071e">policy_eval</a>,discount_factor=0.1)</td></tr>
<tr class="separator:a1d53a65de36fee8cbe6d35f10af91a31"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae530627414b0b1708a31b9502ea2ad0f"><td class="memItemLeft" align="right" valign="top">tuple&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacefeeder__offline__training.html#ae530627414b0b1708a31b9502ea2ad0f">random_policy</a> = np.ones([<a class="el" href="namespaceenv.html#af556ea2d3375dc2b30ca336a438de625">env.nS</a>, <a class="el" href="namespaceenv.html#aac861bd46c3271ef98e116633105a24a">env.nA</a>])</td></tr>
<tr class="separator:ae530627414b0b1708a31b9502ea2ad0f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6f9dce4524c4cbbf3b2a01bbf899c922"><td class="memItemLeft" align="right" valign="top">tuple&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacefeeder__offline__training.html#a6f9dce4524c4cbbf3b2a01bbf899c922">val_iter_policy</a> = <a class="el" href="namespacefeeder__offline__training.html#a6c77911f829708330dcce88228788bdd">value_iteration</a>(discount_factor=0.1)</td></tr>
<tr class="separator:a6f9dce4524c4cbbf3b2a01bbf899c922"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1c6e1d31c5c84df53f4c5df9f8070307"><td class="memItemLeft" align="right" valign="top">tuple&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacefeeder__offline__training.html#a1c6e1d31c5c84df53f4c5df9f8070307">vi_pi_star</a> = <a class="el" href="namespacefeeder__offline__training.html#ae6f2b6c5fc2ee36749b23735b7510238">policyMatrixToVector</a>(<a class="el" href="namespacefeeder__offline__training.html#a6f9dce4524c4cbbf3b2a01bbf899c922">val_iter_policy</a>[0])</td></tr>
<tr class="separator:a1c6e1d31c5c84df53f4c5df9f8070307"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6c5664e785921789a66597e3fb7d275b"><td class="memItemLeft" align="right" valign="top">list&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacefeeder__offline__training.html#a6c5664e785921789a66597e3fb7d275b">VI_pi_star_file</a> = sys.argv[1]</td></tr>
<tr class="separator:a6c5664e785921789a66597e3fb7d275b"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<h2 class="groupheader">Function Documentation</h2>
<a class="anchor" id="a6b2e776b125a379926ab2906f86c071e"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def feeder_offline_training.policy_eval </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>policy</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>discount_factor</em> = <code>1.0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>theta</em> = <code>0.00001</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Evaluate a policy given an environment and a full description of the environment's dynamics.

Args:
    policy: [S, A] shaped matrix representing the policy.
    env: OpenAI env. env.P represents the transition probabilities of the environment.
        env.P[s][a] is a list of transition tuples (prob, next_state, reward, done).
        env.nS is a number of states in the environment. 
        env.nA is a number of actions in the environment.
    theta: We stop evaluation once our value function change is less than theta for all states.
    discount_factor: Gamma discount factor.

Returns:
    Vector of length env.nS representing the value function.
</pre> 
<p>Definition at line <a class="el" href="feeder__offline__training_8py_source.html#l00019">19</a> of file <a class="el" href="feeder__offline__training_8py_source.html">feeder_offline_training.py</a>.</p>

</div>
</div>
<a class="anchor" id="a4dfb6a04eab78e4c049f70307b2025ef"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def feeder_offline_training.policy_iteration </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>policy_eval_fn</em> = <code>policy_eval</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>discount_factor</em> = <code>1.0</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Policy Improvement Algorithm. Iteratively evaluates and improves a policy
until an optimal policy is found.

Args:
    env: The OpenAI envrionment.
    policy_eval_fn: Policy Evaluation function that takes 3 arguments:
        policy, env, discount_factor.
    discount_factor: gamma discount factor.
    
Returns:
    A tuple (policy, V). 
    policy is the optimal policy, a matrix of shape [S, A] where each state s
    contains a valid probability distribution over actions.
    V is the value function for the optimal policy.</pre> 
<p>Definition at line <a class="el" href="feeder__offline__training_8py_source.html#l00053">53</a> of file <a class="el" href="feeder__offline__training_8py_source.html">feeder_offline_training.py</a>.</p>

</div>
</div>
<a class="anchor" id="ae6f2b6c5fc2ee36749b23735b7510238"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def feeder_offline_training.policyMatrixToVector </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>policy</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Definition at line <a class="el" href="feeder__offline__training_8py_source.html#l00167">167</a> of file <a class="el" href="feeder__offline__training_8py_source.html">feeder_offline_training.py</a>.</p>

</div>
</div>
<a class="anchor" id="a6c77911f829708330dcce88228788bdd"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def feeder_offline_training.value_iteration </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>theta</em> = <code>0.0001</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>discount_factor</em> = <code>1.0</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Value Iteration Algorithm.

Args:
    env: OpenAI env. env.P represents the transition probabilities of the environment.
        env.P[s][a] is a list of transition tuples (prob, next_state, reward, done).
        env.nS is a number of states in the environment. 
        env.nA is a number of actions in the environment.
    theta: We stop evaluation once our value function change is less than theta for all states.
    discount_factor: Gamma discount factor.
    
Returns:
    A tuple (policy, V) of the optimal policy and the optimal value function.        
</pre> 
<p>Definition at line <a class="el" href="feeder__offline__training_8py_source.html#l00109">109</a> of file <a class="el" href="feeder__offline__training_8py_source.html">feeder_offline_training.py</a>.</p>

</div>
</div>
<h2 class="groupheader">Variable Documentation</h2>
<a class="anchor" id="a6f72d1398884834aeb54ed5d16c326ba"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">tuple feeder_offline_training.pi_pi_star = <a class="el" href="namespacefeeder__offline__training.html#ae6f2b6c5fc2ee36749b23735b7510238">policyMatrixToVector</a>(<a class="el" href="namespacefeeder__offline__training.html#a1d53a65de36fee8cbe6d35f10af91a31">pol_iter_policy</a>[0])</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Definition at line <a class="el" href="feeder__offline__training_8py_source.html#l00198">198</a> of file <a class="el" href="feeder__offline__training_8py_source.html">feeder_offline_training.py</a>.</p>

</div>
</div>
<a class="anchor" id="a39f347ada3f7a0614cff24945645320a"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">string feeder_offline_training.PI_pi_star_file = sys.argv[2]</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Definition at line <a class="el" href="feeder__offline__training_8py_source.html#l00217">217</a> of file <a class="el" href="feeder__offline__training_8py_source.html">feeder_offline_training.py</a>.</p>

</div>
</div>
<a class="anchor" id="a1d53a65de36fee8cbe6d35f10af91a31"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">tuple feeder_offline_training.pol_iter_policy = <a class="el" href="namespacefeeder__offline__training.html#a4dfb6a04eab78e4c049f70307b2025ef">policy_iteration</a>(<a class="el" href="namespacefeeder__offline__training.html#a6b2e776b125a379926ab2906f86c071e">policy_eval</a>,discount_factor=0.1)</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Definition at line <a class="el" href="feeder__offline__training_8py_source.html#l00195">195</a> of file <a class="el" href="feeder__offline__training_8py_source.html">feeder_offline_training.py</a>.</p>

</div>
</div>
<a class="anchor" id="ae530627414b0b1708a31b9502ea2ad0f"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">tuple feeder_offline_training.random_policy = np.ones([<a class="el" href="namespaceenv.html#af556ea2d3375dc2b30ca336a438de625">env.nS</a>, <a class="el" href="namespaceenv.html#aac861bd46c3271ef98e116633105a24a">env.nA</a>])</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Definition at line <a class="el" href="feeder__offline__training_8py_source.html#l00200">200</a> of file <a class="el" href="feeder__offline__training_8py_source.html">feeder_offline_training.py</a>.</p>

</div>
</div>
<a class="anchor" id="a6f9dce4524c4cbbf3b2a01bbf899c922"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">tuple feeder_offline_training.val_iter_policy = <a class="el" href="namespacefeeder__offline__training.html#a6c77911f829708330dcce88228788bdd">value_iteration</a>(discount_factor=0.1)</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Definition at line <a class="el" href="feeder__offline__training_8py_source.html#l00194">194</a> of file <a class="el" href="feeder__offline__training_8py_source.html">feeder_offline_training.py</a>.</p>

</div>
</div>
<a class="anchor" id="a1c6e1d31c5c84df53f4c5df9f8070307"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">tuple feeder_offline_training.vi_pi_star = <a class="el" href="namespacefeeder__offline__training.html#ae6f2b6c5fc2ee36749b23735b7510238">policyMatrixToVector</a>(<a class="el" href="namespacefeeder__offline__training.html#a6f9dce4524c4cbbf3b2a01bbf899c922">val_iter_policy</a>[0])</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Definition at line <a class="el" href="feeder__offline__training_8py_source.html#l00197">197</a> of file <a class="el" href="feeder__offline__training_8py_source.html">feeder_offline_training.py</a>.</p>

</div>
</div>
<a class="anchor" id="a6c5664e785921789a66597e3fb7d275b"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">string feeder_offline_training.VI_pi_star_file = sys.argv[1]</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Definition at line <a class="el" href="feeder__offline__training_8py_source.html#l00216">216</a> of file <a class="el" href="feeder__offline__training_8py_source.html">feeder_offline_training.py</a>.</p>

</div>
</div>
</div><!-- contents -->

<br clear="all" />
<hr size="1"><div style="align: right;">
<a href="http://wiki.ros.org/drinking_assistant">drinking_assistant</a><br />
Author(s): tejas</br />
<small>autogenerated on Fri May 24 2019 11:11:42</small>
</div>
</body>
</html>
